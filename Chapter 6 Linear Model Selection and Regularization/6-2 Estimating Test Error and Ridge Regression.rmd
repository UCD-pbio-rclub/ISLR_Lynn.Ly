---
title: "Chapter 6-2"
author: "Lynn Ly"
date: "February 26, 2018"
output: html_document
---

Estimating Test Error Using Mallow's Cp, AIC, BIC, Adjusted R-squared  
Estimating Test Error Using Cross Validation  
Shrinkage Methods and Ridge Regression

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
```

### 6.5.3 Choosing Among MOdels Using the Validation Set Approach and Cross-Validation

We must use only the training observations to perform all aspects of model-fitting, including variable selection. If the full data set is used, then the validation and CV errors will not be accurate estimates of the test error. 

```{r}
set.seed(1)
train = sample(c(TRUE, FALSE), nrow(Hitters), rep = TRUE)
test = !train

regfit.best <- regsubsets(Salary~., data = Hitters[train, ], nvmax= 19)

test.mat <- model.matrix(Salary~., data = Hitters[test, ])
```

Extract the coefs from regfit.best and multiply them into the appropriate columns of the test model matrix to form the predictions, then compute the test MSE
```{r}
val.errors = rep(NA, 19)
for (i in 1:19) {
  coefi <- coef(regfit.best, id = i)
  pred <- test.mat[, names(coefi)] %*% coefi
  val.errors[i] <- mean((Hitters$Salary[test] - pred)^2)
}
```

This suggest the 10 variable model is best. 
NOW, FIT THE 10-VARIABLE MODEL ON THE FULL DATA. These are the coefs you should use. 

### 6.6.1 Ridge Regression 

Q3

Q4

Q5a, b

Q9a, b, c